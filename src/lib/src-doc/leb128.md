# @file leb128.c

ULEB-128 (unsigned) and SLEB-128 (signed, aka, possibly negative
integers) are variable length encodings for possibly "very large"
numbers. I first came across LEB while working with "DWARF2" in in
the 1990s. Google uses the same encoding for unsigned integers but
uses "zig-zag" for signed numbers (the sign bit is stored in the
lowest bit instead of the more complicated technique SLEB-128
uses).

Essentially the 8th bit of each byte says whether to continue
adding bits from the next byte or if the number is now "complete"
(so 7-bits per byte are the real data and 1-bit is
"overhead"). Since many numbers we deal with are actually small,
LEB encoding tend to be an efficient encoding of integers and grow
"gracefully" to accomodate larger numbers. In fact the "128" in
ULEB-128 is a misnomer -- you could in theory encode more than 128
bits. This implementation only reads 64bit numbers, not the full
128 bits.

This implementation originally comes from LLVM although I have
changed it to a C file, renamed the functions, got rid of camel
case, removed the C++ namespace, removed the inline directive,
removed the pad to argument and changed how results and errors are
returned.
 
## @function

Utility function to encode a ULEB128 value to a raw byte
buffer. Returns the length in bytes of the encoded value. 10 bytes
should be enough to hold the 64bit number after encoding.
 
## @function decode_sleb_128

Decode a SLEB128 value (up to 64bits)
 
## @function decode_uleb_128

Decode a ULEB-128 value (up to 64bits).
 
## @function encode_sleb_128

Utility function to encode a SLEB128 value to a raw byte
buffer. Returns the length in bytes of the encoded value. 10 bytes
should be enough to hold the 64bit number after encoding.
 
